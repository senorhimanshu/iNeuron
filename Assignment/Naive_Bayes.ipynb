{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tWhat is conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional probability of an event B is the probability that the event will occur given the knowledge that an event A has already occurred. This probability is written P(B|A), notation for the probability of B given A. In the case where events A and B are independent (where event A has no effect on the probability of event B), the conditional probability of event B given event A is simply the probability of event B, that is P(B).\n",
    "\n",
    "In probability theory and statistics,* Bayes’s theorem** (alternatively *Bayes’s law or Bayes’s rule) describes the probability of an event, based on prior knowledge of conditions that might be related to the event. Mathematically, it can be written as:\n",
    "\n",
    "![](bayes.png)\n",
    "\n",
    "Where A and B are events and P(B)≠0\n",
    "* P(A|B) is a conditional probability: the likelihood of event A occurring given that B is true.\n",
    "* P(B|A) is also a conditional probability: the likelihood of event B occurring given that A is true.\n",
    "* P(A) and P(B) are the probabilities of observing A and B respectively; they are known as the marginal probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tDiscuss Bayes’s theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In probability theory and statistics,* Bayes’s theorem** (alternatively *Bayes’s law or Bayes’s rule) describes the probability of an event, based on prior knowledge of conditions that might be related to the event. Mathematically, it can be written as:\n",
    "\n",
    "![](bayes.png)\n",
    "\n",
    "Where A and B are events and P(B)≠0\n",
    "* P(A|B) is a conditional probability: the likelihood of event A occurring given that B is true.\n",
    "* P(B|A) is also a conditional probability: the likelihood of event B occurring given that A is true.\n",
    "* P(A) and P(B) are the probabilities of observing A and B respectively; they are known as the marginal probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tExplain the step by step working of Naïve Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tLet’s consider that we have a binary classification problem i.e., we have two classes in our data as shown below.\n",
    "<img src=\"bayes1.png\" style=\"width:500px;height:300px\"/>\n",
    "2.\tNow suppose if we are given with a new data point, to which class does that point belong to?\n",
    "<img src=\"bayes2.png\" style=\"width:500px;height:300px\"/>\n",
    "3.\tThe formula for a point ‘X’ to belong in class1 can be written as:\n",
    "<img src=\"bayes3.png\" style=\"width:500px;height:300px\"/>\n",
    "Where the numbers represent the order in which we are going to calculate different probabilities.\n",
    "4.\tA similar formula can be utilised for class 2 as well.\n",
    "5.\tProbability of class 1 can be written as:\n",
    "$P(class1)=\\frac{Number of points in class1}{Total number of points}= \\frac {16}{26}=0.62$\n",
    "6.\tFor calculating the probability of X, we draw a circle around the new point and see how many points(excluding the new point) lie inside that circle.\n",
    "<img src=\"bayes4.png\" style=\"width:500px;height:300px\"/>\n",
    "\n",
    "The points inside the circle are considered to be similar points. \n",
    "$P(X)=\\frac{Number of similar observation}{Total Observations}=\\frac {3}{26}=0.12$\n",
    "7.\tNow, we need to calculate the probability of a point to be in the circle that we have made given that it’s of class 1.\n",
    "$P(X | Class1)= \\frac {Number of points in class 1 inside the circle}{Total number of points in class 1}=\\frac{1}{16}=0.06$\n",
    "8.\tWe can substitute all the values into the formula in step 3. We get:\n",
    "$P(Class1 | X)=\\frac{0.06*0.62}{0.12}=0.31$\n",
    "9.\tAnd if we calculate the probability that X belongs to Class2, we’ll get 0.69. It means that our point belongs to class 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tHow is Naïve Bayes different from other classification algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major difference in the way in which the Naïve Bayes algorithm works form other classification algorithms is that, It does not first try to learn how to classify the points. It directly uses the label to identify the two separate classes and then it predicts the class to which the new point shall belong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tWhy is the algorithm called Naïve Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire algorithm is based on Bayes’s theorem to calculate probability. So, it also carries forward the assumptions for the Bayes’s theorem. But those assumptions(that the features are independent) might not always be true when implemented over a real-world dataset. So, those assumptions are considered Naïve and hence the name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tWhat is Gaussian Naïve Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with continuous data, a typical assumption is that the continuous values associated with each class are distributed according to a Gaussian distribution. Go back to the normal distribution lecture to review the formulas for the Gaussian/Normal Distribution.\n",
    "\n",
    "For example of using the Gaussian Distribution, suppose the training data contain a continuous attribute, x. We first segment the data by the class, and then compute the mean and variance of x in each class. Let  μ<sub>c</sub> be the mean of the values in x associated with class c, and let  σ<sup>2</sup><sub>c</sub> be the variance of the values in x associated with class c. Then, the probability distribution of some value given a class, p(x=v|c), can be computed by plugging v into the equation for a Normal distribution parameterized by μ<sub>c</sub> and  σ<sup>2</sup><sub>c</sub>. That is:\n",
    "\n",
    "$$p(x=v|c)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_c}}\\,e^{ -\\frac{(v-\\mu_c)^2}{2\\sigma^2_c} }$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tWhat are the advantages and disadvantages of Naïve Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "* Naive Bayes is extremely fast for both training and prediction as they not have to learn to create separate classes.\n",
    "* Naive Bayes provides a direct probabilistic prediction.\n",
    "* Naive Bayes is often easy to interpret.\n",
    "* Naive Bayes has fewer (if any) parameters to tune\n",
    "\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "* The algorithm assumes that the features are independent which is not always the scenario\n",
    "* Zero Frequency i.e. if the category of any categorical variable is not seen in training data set even once then model assigns a zero probability to that category and then a prediction cannot be made."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
